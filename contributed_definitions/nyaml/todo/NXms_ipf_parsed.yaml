category: base
doc: |
  Base class to store an inverse pole figure mapping.
symbols:
  # how to make this optional
  n_z: |
    Number of pixel along the z slowest direction.
  n_y: |
    Number of pixel along the y slow direction.
  n_x: |
    Number of pixel along the x fast direction.
  n_rgb: |
    Number of RGB values along the fastest direction, always three.
type: group
NXms_ipf(NXprocess):
  projection_direction(R):
    doc: |
      The direction along which orientations are projected.
    unit: NX_UNITLESS
    dim: (3,)
  map(NXdata):
    doc: |
      Inverse pole figure mapping.
    info: |  # this info block should be shortened
      Default inverse pole figure (IPF) plot of the data specific for each
      phase. No ipf_mapID instances for non-indexed scan points as these are
      by definition assigned the null phase with phase_identifier 0.
      
      The IPF mapping is interpolated from the scan point data mapping
      onto a rectangular domain with square pixels and the
      orientations colored according to the coloring scheme used in the
      respective ipf_color_modelID/program.
      
      The main purpose of the ipf_mapID group is not to keep raw data or
      scan point related data but offer a default way how a research data
      management system can display a preview of the dataset so that users
      working with the RDMS can get an overview of the dataset.
      
      This matches the first aim of NXem_ebsd which is foremost to bring
      colleagues and users of EBSD together to discuss which pieces of information
      need to be stored together. We are convinced a step-by-step design and
      community-driven discussion about which pieces of information should
      and/or need to be included is a practical strategy to work towards an
      interoperable description and data model for exchanging
      data from EBSD between different tools and research data management
      systems (RDMS).
      
      With this design the individual RDMS solutions and tools can still continue
      to support specific custom data analyses workflow and routes but at least
      there is then one common notation of understanding whereby also users
      not necessarily expert in all the details of the EBSD story can understand
      better these data and thus eventually this can motivate data reuse and
      repurposing.
      
      It is important to mention that we cannot assume, at least for now,
      that the parser which writes to an NXem_ebsd-compliant file is also
      responsible or capable at all of computing the inverse pole figure
      color keys and maps itself. This cannot be assumed working because
      this mapping of orientation data uses involved mathematical algorithms
      and functions which not every tools used in the EBSD community is capable
      of using or is for sure not using in exactly the same way.
      
      Currently, we assume it is the responsibilty of the tool used which
      generated the data under on_the_fly_indexing to compute these
      plots and deliver these to the parser.
      
      Specific case studies have been explored by the experiment team of
      Area B of the FAIRmat project to realize and implement such mapping.
      
      The first case study uses the H5OINA format and the pyxem/orix library.
      As orix is a Python library, the coloring is performed by the em_om parser.
      
      The second case study uses MTex and its EBSD color coding model.
      As MTex is a Matlab tool, an intermediate format is written from MTex
      first which stores these pieces of information. The parser then pulls
      these data from the intermediate Matlab-agnostic representation and
      supplements the file with missing pieces of information as it is
      required by NXem_ebsd.
      
      The third case study shows how a generic set of Kikuchi pattern
      can be loaded with the em_om parser. The pattern are loaded directly
      from a ZIP file and mapped to an simulation image section for now.
      
      The fourth case study uses the DREAM.3D package which provides an own
      set of EBSD data post-processing procedures. DREAM.3D documents the
      processing steps with a pipeline file which is stored inside DREAM.3D
      output files. In this case study, the parser reads the DREAM.3D file
      and maps data relevant from the perspective of NXem_ebsd plus adds
      relevant IPF color maps as they were computed by DREAM.3D.
      Given that in this case the origin of the data is the DREAM.3D file
      again provenance is kept and more details can be followed upon when
      resolving origin.
      
      These examples offer a first set of suggestions on how to make EBSD
      data injectable into research data management system using schemes
      which themselves are agnostic to the specific RDMS and interoperable.
      Steps of collecting the raw data and post-processing these with custom
      scripts like MTex or commercial tools so far are mainly undocumented.
      The limitation is that a program which consumes results or dump files
      from these tools may not have necessarily all the sufficient information
      available to check if the injected orientation data and color models
      are matching the conventions which a user or automated system has
      injected into an electronic lab notebook from which currently the em_om
      parser collects the conventions and stores them into this NXem_ebsd instance.
      The immediate benefit of the here presented NXem_ebsd concept though
      is that the conventions and reference frame definitions are expected
      in an ELN-agnostic representation to make NXem_ebsd a generally useful
      data scheme for EBSD.
      
      Ideally, the em_om parser would load convention-compliant EBSD data
      and use subsequently a community library to transcode/convert orientation
      conventions and parameterized orientation values. Thereafter, convention-
      compliant default plot(s) could be created that would be truely interoperable.
      
      However, given the variety of post-processing tools available surplus
      the fact that these are not usually executed along standardized
      post-processing workflows which perform exactly the same algorithmic steps,
      this is currently not a practically implementable option. Indeed, first
      developers who wish to implement this would first have to create a library
      for performing such tasks, mapping generally between conventions,
      i.e. map and rotate coordinate systems at the parser level.
      
      The unfortunate situation in EBSD is that due to historical reasons
      and competitive strategies, different players in the field have
      implemented (slightly) different approaches each of which misses
      some part of a complete workflow description which is behind EBSD analyses:
      Sample preparation, measurement, indexing, post-processing, paper...
      
      The here exemplified default plot do not so far apply relevant rotations
      but takes the orientation values as they come from the origin and using
      coloring them as they come. It is thus the scientists responsibility to
      enter and check if the respective dataset is rotation-conventions-wise
      consistent and fit for a particular task.
      
      Ideally, with all conventions defined it can be possible to develop
      a converter which rotates the input data. This application definition
      does not assume this and users should be aware of this limitation.
      
      The key point is that the conventions however are captured and this is
      the most important step to the development of such a generic transcoder
      for creating interoperable EBSD datasets.
      
      Currently the conventions remain in the mind or manual lab book of the
      respective scientists or technicians instead of getting stored and
      communicated with research papers that are written based on
      specific dataset, i.e. database entries.
      
      The default gridded representation of the data should not be
      misinterpreted as the only possible way how EBSD data and OIM
      maps can be created!
      
      Indeed, the most general case is that patterns are collected for
      scan points. The scan generator of an electron microscope is instructed
      to steer the beam in such a way across the specimen surface that the
      beam illuminates certain positions for a certain amount time (usually
      equally-spaced and spending about the same amount of time at each
      position).
      
      Therefore, scan positions can be due to such regular flight plans and
      represent sampling on lines, line stacks, rectangular regions-of-
      interests, but also could instruct spiral, random, or adaptive scans
      instead of tessellations with square or hexagonal pixels.
      
      The majority of EBSD maps is though is reporting results for a regular
      grid (square, hexagon). What matters though in terms of damage induced
      by the electron beam and signal quality is the real electron dose
      history, i.e. for how long the beam exposed which location of the
      specimen. Especially when electron charging occurs (i.e. an excess
      amount of charge accumulates due to e.g. poor conducting away of this
      charge or an improper mounting, too high dose, etc. such details are
      relevant.
      
      Specifically, the default visualization is an inverse pole-figure (IPF)
      map with the usual RGB color coding. Different strategies and
      normalization schemes are in use to define such color coding.
      
      Finally, we should mention that each ipf_map represents data for
      scan points indexed as one phase. The alias/name of this phase should
      be stored in phase_name, the phase_identifier give an ID which must
      not be zero as this value is reserved for non-indexed / null model scan
      points.
    # \@signal: data
    # \@axes: [axis_y, axis_x]
    # \@axis_x_indices: 0
    # \@axis_y_indices: 1
    data(N0):
      unit: NX_UNITLESS
      # hehe, but can be larger than one but could also be an NX_DIMENSIONLESS !
      doc: |
        Inverse pole figure color code for each map coordinate.
      dim: (n_y, n_x, 3)  # | (n_z, n_y, n_x, 3)
    axis_z(R):
      unit: NX_LENGTH
      doc: |
        Pixel center along the z axis of the map.
      dim: (n_z,)
      # \@long_name:
    axis_y(R):
      unit: NX_LENGTH
      doc: |
        Pixel center along the y axis of the map.
      dim: (n_y,)
      # \@long_name:
    axis_x(R):
      unit: NX_LENGTH
      doc: |
        Pixel center along the x axis of the map.
      dim: (n_x,)
      # \@long_name:
    # title:
  legend(NXdata):
    doc: |
      The color code which represents how orientations about positions
      in the fundamental zone of orientation space are mapped
      to an RGB triplet each.
      
      For each stereographic standard triangle (SST), i.e. a rendering of
      the fundamental zone of the crystal-symmetry-reduced orientation space
      SO3, it is possible to define a color model which assigns each point in
      the fundamental zone a color.
      Different mapping models are used. These implement (slightly) different
      scaling relations. Differences are which base colors of the RGB
      color model are placed in which extremal position of the SST
      and where the white point is located. For further details see:
      
      * [G. Nolze et al.](https://doi.org/10.1107/S1600576716012942)
      * Srikanth Patala and coworkers"'" work and of others.
      
      Details are implementation-specific and not standardized yet.
    info: |
      Given that the SST has a complicated geometry, it cannot yet be
      visualized using tools like H5Web, which is why for now the matrix
      of a rasterized image which is rendered by the backend tool gets injected
      as the default plot.
    # \@signal: data
    # \@axes: [axis_y, axis_x]
    # \@axis_x_indices: 0
    # \@axis_y_indices: 1
    data(N0):
      unit: NX_UNITLESS
      # hehe, but can be larger than one but could also be an NX_DIMENSIONLESS !
      doc: |
        Inverse pole figure color code for each map coordinate.
      dim: (n_y, n_x, 3)
    axis_y(R):
      unit: NX_LENGTH
      doc: |
        Pixel along the y-axis.
      dim: (n_y,)
      # \@long_name:
    axis_x(R):
      unit: NX_LENGTH
      doc: |
        Pixel along the x-axis.
      dim: (n_x,)
      # \@long_name:
    # title:
