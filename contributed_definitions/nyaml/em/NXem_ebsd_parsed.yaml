category: base
doc: |
  Base class method-specific for Electron Backscatter Diffraction (EBSD).
info: |
  The general procedure of an EBSD experiment is as follows:
  Users load the specimen, collect first a coarse image of the surface.
  Next, they set an approximate value for the calibrated working distance
  tilt the stage to diffraction conditions.
  
  Users then may configure the microscope for collecting higher quality data
  and push in the EBSD detector. Subsequently, they fine tune the illumination
  and aberration corrector settings and select one or multiple ROIs for
  the microscope to machine off automatically. On-the-fly indexing parameter
  are configured and the measurement queue started.
  
  Nowadays, this is in most cases an automated process. The pattern
  collection runs during the allocated microscope session until the
  queue finishes or gets interrupted by errors or the next user.
  
  Kikuchi pattern surplus eventually multi-modal detector signals are
  collected and usually indexed on-the-fly. Patterns may be stored or not
  so one should not assume that raw data are always stored.
  
  Results are stored in files, which afterwards are typically copied
  automatically or manual for archival purposes to certain storage
  locations or further consumption. The result of such an EBSD
  measurement/experiment is a set of usually proprietary or open files
  from technology partners.
  
  This base classNXem_ebsd application is a proposal how to represent data, metadata, and
  connections between these for the research field of electron microscopy.
  More specifically, exemplified here for electron backscatter diffraction (EBSD).
  The application definition solves two key documentation issues which are missing
  so far to document provenance of data and metadata in the field of EBSD.
  The application definition can be an example that is relevant for related
  workflows in orientation microscopy.
  
  Firstly, an instance of NXem_ebsd (such as a NeXus/HDF5 file which is formatted
  according to the NXem_ebsd application definition) stores the connection between
  the microscope session and the key datasets which are considered typically results
  of the various processing steps involved when working with EBSD data.
  
  Different groups in this application definition make connections to data artifacts
  which were collected when working with electron microscopes via the NXem partner
  application definition. Using a file which stores information according to the
  NXem application definition has the benefit that it connects the sample, references
  to the sample processing, the user operating the microscope, details about the
  microscope session, and details about the acquistion and eventual indexing of
  Kikuchi pattern, associated overview images, like secondary electron or
  backscattered electron images of the region-of-interest probed and many
  more pieces of information.
  
  Secondly, this NXem_ebsd application definition connects and stores the conventions
  and reference frames which were used and are the key to mathematically correctly
  interpret every EBSD result. Otherwise, results would be ripped out of their
  context, as it is the situation with many traditional studies where EBSD data were
  indexed on-the-fly and shared with the community only via sharing the results file
  with some technology-partner-specific file but leaving important conventions out
  or relying on the assumptions that colleagues know these even though multiple
  definitions are possible.
  
  This application definition covers experiments with one-, two-dimensional, and
  so-called three-dimensional EBSD datasets. The third dimension is either time
  (in the case of quasi in-situ experiments) or space (in the case of serial-
  sectioning) methods where a combination of mechanical or ion milling is used
  repetitively to measure the same region-of-interest at different depth increments.
  Material removal can be achieved with electron or ion polishing, using manual
  steps or using automated equipment like a robot system.
  
  Three-dimensional experiments require to follow a sequence of specimen, surface
  preparation, and data collection steps. By nature these methods are destructive
  in that they either require the removal of the previously measured material region
  or that the sample surface can degrade due to e.g. contamination or other
  electron-matter interaction.
  
  For three-dimensional EBSD, multiple two-dimensional EBSD orientation mappings are
  combined into one reconstructed stack. That is serial-sectioning is mainly a
  computational workflow. Users collect data for each serial sectioning step
  via an experiment. This assures that data for associated microscope sessions
  and steps of data processing stay connected and contextualized.
  
  Eventual tomography methods also use such a workflow because first diffraction
  images are collected (e.g. with X-ray) and then these imagres are indexed and
  computed into a 3D orientation mapping. The here proposed NXem_ebsd application
  definition contains conceptual ideas how this splitting between measurement and
  post-processing can be granularized also for such X-ray-based techniques, whether
  it be 3DXRD or HEDM.
symbols:
  n_op: |
    Number of arguments per orientation for given parameterization.
  n_sc: |
    Number of scan points.
  n_z: |
    Number of pixel along the slowest changing dimension for a rediscretized, 
    i.e. standardized default plot orientation mapping.
  n_y: |
    Number of pixel along slow changing dimension for a rediscretized i.e.
    standardized default plot orientation mapping.
  n_x: |
    Number of pixel along fast changing dimension for a rediscretized i.e.
    standardized default plot orientation mapping.

# The respective partner application definition NXxray_fourd
# can be used for storing data and post-processing results of X-ray diffraction
# experiments which can yield also orientation maps in one, two- or three-dimensions.
# These complementary techniques and associated application definitions can be used
# to inform NXms, another partner application definition to NXem_ebsd. NXms describes
# the connection between measured or simulated structural features with a focus of
# the length and time-scale coarser then the atomic scale. The term microstructure
# is used here but is not restricted to features at the micron scale.

# the IUCr DMI should work on an e.g. NXhedm
# NXem_tkd is not needed as it can be covered by NXem_ebsd as well.
# if we think of the metadata/data graph collected from the microscope session
# documented in NXem there may be only a few relations between nodes of an instance
# of NXem_ebsd and NXem. Key data from NXem which many users would expect to find
# also enumerated in NXem_ebsd could be settings of the microscope, timestamp data
# when tasks were performed at the microscope using which specimen, operated
# and prepared by whom. These latter pieces of information are all available
# in NXem but if we were to make fields in NXem deep inside an instance
# of NXem_event_data required than we factually more and more granularize and
# pull in steps of detailed numerical post-processing which arguably is not
# any longer at all necessarily related to the microscope session.
# We know many cases in EBSD community, see the work of e.g. Marc de Graef's group
# or of Hakon Wiik Anes and Knut Marthinsen who spent much longer with a collected
# dataset in post-processing than collecting it at the microscope. Therefore, we
# need to have the flexibility that documentation of the actual microscope session
# and the post-processing of some of the data therein collected remain coupled
# but not too repetively and with too stiff constraints on the existence of specific
# fields as otherwise there can be contradictions for which NXem_ebsd would no longer
# be applicable when one wishes to remain at the same time conformant with the data
# scheme.
# The idea used here is to use a reference to another NeXus file in the NXem_ebsd
# file instance and the NXem file instance. So far we acknowledge that exporting
# data as an NXem application definition is limited and scientists currently have
# specific file formats from commercial or open-source tools to work with.
# Therefore, we so far model the connections between the application definitions
# as NXprocesses. As soon as NXem is more supported these NXclasses should become
# NXem e.g. though.
# Details about scan positions should not be reproduced unless needed for
# interpolating between results of neighboring scan positions.
# Currently, we suggest to leave the scan positions as closely to where they are
# collected, i.e. inside NXem.
# What this exampe of linking information rather than duplicating shows is that
# somewhat a culture change is needed: Instead of packing everything in one file
# we just need to assure that we have a tool whereby we can follow and inspect a
# set of linked objects if you would like to say so, also having multiple files
# is okay.
# Finally, this application definition makes any assumptions about
# gridding, this enables to handle all sort of scan schemes.
# We follow the argumentation of MTex, in certain cases data will not yield
# fully occupied grids anyway.
# NXem_ebsd could also be useful/used for storing generic simulations of EBSD pattern
# which is one example for simulations of diffractions patterns as they may be observed
# with electron microscopes. In this case, there should be simulation(NXprocess) under this
# the simulation group where one can store the minimum required set of pieces of information
# which comes with every diffraction pattern simulation.
# The main problem is in this case that the simulation group is required but then there must
# either be no measurement group and on_the_fly_indexing group, and eventually calibration ?
# or these groups should be created but remain empty.
# Using the current NeXus appdef design and rules for setting constraints demands that then the
# same appdef should be used for post-processing measured data. So there is a conflict:
# The simulation must not be required and measurement must not be optional.
# Arguably one may call for two application definitions in this case but most constraints and
# concepts would then match those of NXem_ebsd which works again standardization and
# reducing the total number of ontologies.
type: group
NXem_ebsd(NXem_method):
  conventions(NXem_conventions):
  # either we have simulated data or we have a set of measured data
  # in every case data are Kikuchi diffraction pattern and their metadata
  measurement(NXprocess):
    doc: |
      This group documents relevant details about the conditions and the tools
      used for measuring a stack of Kikuchi diffraction pattern with an
      electron microscope.
    info: |
      The most frequently collected EBSD data are captured as for rectangular
      regions-of-interested which are sampled with regular square or
      hexagonally-shaped pixels. 
    # The em_om parser will currently not interpret the majority of the
    # many system- and technique-specific metadata which come with the
    # files from e.g. technology partners. This is because the current
    # culture in the EBSD community is that many of the metadata fields
    # are neither in all cases fully documented nor use a standardized
    # vocabulary although many people understand terms from different
    # implementations and how these metadata can likely be compared to
    # one another.
    # 
    # In addition, it is common practice in the research field of EBSD that
    # users transcode their raw data into other (often text-based or HDF5)
    # files with custom formatting to realize an information transfer
    # between specific software tools including commercial software from
    # technology partner, custom scripts in Matlab using tools like MTex,
    # or Python scripting with tools like hyperspy, pyxem, orix, diffsims,
    # kikuchipy, or EBSD data stack alignment tools like DREAM.3D.
    # We have opted that in the first iteration this implementation of a
    # RDMS-agnostic FAIR data schema for EBSD that we discard these metadata
    # because these ad hoc file formats are not designed to communicate
    # also specifically and most importantly the eventually different context
    # of the metadata.
    # Another reason for this choice was also to emphasize that in fact such
    # challenges do exist in the community and thus pointing them out may
    # support the discussion to arrive at eventually more complete solutions.
    # As developing these solutions should not be our authority and necessarily
    # demands feedback from the technology partners, we have opted for this
    # intermediate approach to stimulate discussion.
    # sequence_index(N):
    #   unit: NX_UNITLESS
    time(NX_TIME):
      unit: NX_TIME
      doc: |
        Physical time since the beginning of a timestamp that is required to be
        same for all experiments in the set. The purpose of this marker is
        to identify how all experiments in the set have have to be arranged
        sequentially based on the time elapsed.
        The time is relevant to sort e.g. experiments of consecutive quasi
        in-situ experiments where a measurement was e.g. taken after 0 minutes
        of annealing, 30 minutes, 6 hours, or 24 hours of annealing.
    # (NXtransformations):
    #   doc: |
    #     Transformation which details where the region-of-interest described under
    #     indexing is located in absolute coordinates and rotation with respect
    #     to which coordinate system.
    pattern_available(NX_BOOLEAN):
      doc: |
        True if either the depends_on or origin field specify the actual
        Kikuchi pattern stack with which the indexing is performed.
        False if this information is not available.
    depends_on:
      doc: |
        Reference to a location (in an application definition instance) which
        specifies the stack. If this field is used, the reference has to point
        to an existent instance of NXimage_r_set_diff.
        
        Alternatively, use origin if the Kikuchi pattern stack or already processed
        data which should be used as input is available. A typical example is a
        file in common formats e.g. HDF5, CPR, CTF, etc.
    origin:
      doc: |
        Reference (e.g. path and filename) to an existent data artifact which
        stores either the pattern or input (already processed EBSD data)
        which is now processed further as described by this NXem_ebsd instance.
      \@version:
        doc: |
          Commit identifying this resource or at least an as strong as SHA256
          hash generated from the content of the data artifact.
  simulation(NXprocess):
    doc: |
      This group documents relevant details about the conditions and the tools
      used for simulating a stack of Kikuchi diffraction pattern with some model.
      
      This group should not be confused with the reference group: Simulation
      can be used to simulate pattern which one may wish to index maybe because
      no measurements were taken and the study is entirely a simulation.
      
      By contrast the reference group stores eventual pattern which can be
      used e.g. in dictionary based indexing approaches to index pattern from
      simulation or measurement against.
      
      In many practical cases where pattern are analyzed on-the-fly these
      reference or sometimes also called master or lookup pattern are not stored
      but instead a reduced description such as a list of reflectors is provided.
      This latter pieces of information are should be stored in instance of
      NXem_ebsd_crystal_structure_model and references thus may remain empty.
    pattern_available(NX_BOOLEAN):
      doc: |
        True if either the depends_on or origin field specify the actual
        Kikuchi pattern stack with which the indexing is performed.
        False if this information is not available.
    depends_on:
      doc: |
        Reference to a location (in an application definition instance) which
        specifies the stack. If this field is used, the reference has to point
        to an existent instance of NXimage_r_set_diff.
        
        Alternatively, use origin if the Kikuchi pattern stack or already processed
        data which should be used as input is available. A typical example is a
        file in common formats e.g. HDF5, CPR, CTF, etc.
    origin:
      doc: |
        Reference (e.g. path and filename) to an existent data artifact which
        stores either the pattern or input (already processed EBSD data)
        which is now processed further as described by this NXem_ebsd instance.
      \@version:
        doc: |
          Commit identifying this resource or at least an as strong as SHA256
          hash generated from the content of the data artifact.
  calibration(NXprocess):
      doc: |
        The EBSD system, including components like the electron gun, pole-piece,
        stage tilting, EBSD detector, and the gnomonic projection have to be
        calibrated to achieve reliable indexing results. Specifically,
        the gnomonic projection has to be calibrated. Typically silicon or
        quartz crystals are used for this purpose.
      info: |
        In many practical cases it is much more frequently the case that a
        system is considered well-calibrated and thus just used instead that
        one calibrates for the above-mentioned aspects before the measurement
        is taken.
        
        In the first case, the user assumes that the principle geometry of the
        hardware components and the settings in the control and EBSD pattern
        acquisition software has been calibrated. Consequently, users pick from
        an existent library of phase candidates, i.e.
        :ref:`NXem_ebsd_crystal_structure_model` instances. Examples are
        reflector models as stored in CRY files (HKL/Channel 5/Flamenco).
        
        In the second case, the system is being calibrated during the session
        using standards (silicon, quartz, or other common specimens).
        There is usually one person in each lab responsible for doing such
        calibrations. Important is that often this person or technician(s) are also
        in charge of configuring the graphical user interface and software
        with which most users control and perform their analyses.
        For EBSD this has key implications because, taking TSL OIM/EDAX as an example,
        the conventions how orientations are stored is affected by how reference frames
        are set up and this setup is made at the level of the GUI software.
        Unfortunately, these pieces of information are not necessarily stored
        in the results files. In effect, key conventions become disconnected
        from the data so it remains the users personal obligation to remember these
        settings, write them down in the lab notebook, or these metadata get lost.
        All these issues are a motivation and problem which NXem_ebsd solves.
      sequence_index(NX_POSINT):
      calibration_available(NX_BOOLEAN):
        doc: |
          True if calibration data are available and resolvable via either
          depends_on or origin.
      depends_on:
        doc: |
          Reference to a location (in an application definition instance) which
          specifies a calibration measurement. If this field is used,
          the reference has to point to an instance of NXem_base.
          
          Alternatively, use origin if a calibration measurement is available
          only as a file.
      origin:
        doc: |
          Reference (e.g. path and filename) to an existent data artifact which
          stores either a log of the calibration measurement.
        \@version:
          doc: |
            Commit identifying this resource or at least an as strong as SHA256
            hash generated from the content of the data artifact.
  indexing(NXprocess):
    doc: |
      Indexing is a data processing step performed either after or while
      (on-the-fly) the beam scans the specimen. The resulting method is also
      known as orientation imaging microscopy (OIM).
      
      Fundamentally different algorithms can be used to index EBSD/EBSP pattern.
      Common is that pattern indexing is a computational step of comparing
      simulated reference with patterns to index (as referred to via the
      measurement or simulation groups of this base class).
      
      Quality descriptors are defined based on which an indexing algorithm
      yields a quantitative measure of how similar measured and reference
      pattern are, and thus if no, one, or multiple so-called solutions
      were found.
    info: |
      Assumed or simulated pattern are simulated using kinematic or dynamical
      electron diffraction theory. The Hough transform is essentially a
      discretized Radon transform (for details see `M. van Ginkel et al. <https://www.semanticscholar.org/paper/A-short-introduction-to-the-Radon-and-Hough-and-how-Ginkel/fb6226f606cad489a15e38ed961c419037ccc858>`_).
      
      Recently, dictionary-based indexing methods are increasingly becoming used
      partly driven by the interest to use artificial intelligence algorithms.
      
      An inspection of several hundred publicly available EBSD datasets with an
      open-source license via OpenAire was performed prior to implementing
      the examples for the NOMAD OASIS research data management system.
      
      This analysis revealed that EBSD data are in most cases stored in two ways:
      Case one was via a file in formats from technology partners. Examples
      are binary formats like OSC, H5OINA, OIP, EBSP, and many derived
      text-based formats like CPR, CRC, ANG, CTF, HKL and more. 
      Recently, there is trend towards using HDF5-based formats thanks to
      members of the DREAM3D community and the technology partners they were
      able to motivate.
      
      These files contain many results and metadata which contextualize the
      numerical steps and computational workflow whereby Kikuchi pattern were
      indexed. Examples of metadata include scan point positions, indexing
      solutions per scan point, some quality descriptors for the solutions,
      as well as crystal structure and phase metadata.
      
      Case two were raw pattern in some custom format, often text-based with
      some but in general neither a conclusive nor interoperable representation
      of all relevant metadata.
      
      Often it remains unclear what individual fields and data arrays of these
      fields resolve or mean conceptually. For some fields, publications were
      referred to. However, software tools change over time and thus which 
      specific data ended up in the file, with which specific version of software
      or maybe even multiple pieces of software the data were processed remains
      elusive.
      
      Other cases were storing results of custom post-processing steps and
      associated Kikuchi patterns. Testing of advanced indexing, pseudo-symmetry
      resolving methods, i.e. any sort of prototyping or alternative indexing
      strategies, so far seem to call for rapid prototyping capabilities.
      The drawback of this is such results come formatted on a
      case-by-case basis and are thus not interoperable.
      
      Therefore, we first need to collect how these files have been generated
      and which metadata in these files (or database entries) represent
      which pieces of information conceptually. Ideally, one would do so by
      creating a complete set of information in e.g. an NXem application definition,
      such as a log of time-stamped events and processing steps, metadata and data.
      Eventually even interactions with the graphical user interface of commercial
      software during the microscope session should be stored and become a
      part of the application definition.
      
      Such a set of pieces of information could then be used via reading directly
      for the NXem application definition. However, in most cases such a data
      representation is not available yet.
    # sequence_index(N):
    on_the_fly_indexing(NXprocess):
      doc: |
        This group provides a compromise for the dilemna and approach whereby
        to document steps of on-the-fly processing.
      depends_on:
        doc: |
          Reference to the relevant group (either measurement, simulation, 
          or calibration inside this NXem_ebsd group) which resolves the
          data artifact which was generated from this on_the_fly_indexing step.
    method:
      doc: |
        Principal algorithm used for indexing.
      enumeration: [undefined, hough_transform, dictionary, radon_transform, other]
    background_correction(NXprocess):
      doc: |
        Details about the background correction applied to each Kikuchi pattern.
      sequence_index(NX_POSINT):
      # for each process the program used
      # auto_background_correction:
      # static_or_dynamic:
      # pattern_averaging(NXprocess):
      # doc: |
      # Details about how patterns of each scan point are average or how
      # pattern from scan points and neighboring scan points are spatially
      # averaged (using weighting schemes and e.g. kernels) before these
      # patterns are passed to the indexing algorithm.
    binning(NXprocess):
      doc: |
        Binning i.e. downsampling of the pattern.
      sequence_index(NX_POSINT):
    # for each process the program used
    # mode:
    # doc: Free-text description for instrument specific settings
    # binning(NX_UINT): ##MK equivalent to pattern height and width?
    # doc: |
    # How is the camera signal binned.
    # First the number of pixel along the slow direction.
    # Second the number of pixel along the fast direction.
    # unit: NX_UNITLESS
    # dimensions:
    # rank: 1
    # dim: [[1, 2]]
    parameter(NXprocess):
        doc: |
          Specific parameter relevant only for certain algorithms used
        sequence_index(NX_POSINT):
    # mode:
    # doc: Which method used to index pattern?
    # enumeration: [optimize_bd]  # what does optimize_bd mean Oxford?
    (NXem_ebsd_crystal_structure_model):
    # connection to data collected using kinematic or
    # NEW ISSUE: dynamic diffraction theory simulations
    # individual mappings
    # (scientists in EBSD consult all sorts of mappings)
    # like image_quality map, orientation mapping, ipf mapping, grain mapping
    # etc. in fact these could be all the possible mappings which one can
    # create with the famous commercial software solutions
    # the problem a RDMS cannot understand these mappings unless they
    # are standardized in the sense, one has an exchange format whereby
    # these mappings can be exported/transcoded from their representation
    # in the commercial software, e.g.
    # keep in mind, everybody uses the TSL OIM or Bruker AZTec OIM mapping
    # but even these two are not directly interoperable, which is why
    # they are also not interoperable in some RDMS if one does not come
    # up with a way how to go about standardizing their description
    # summary(NXdata):
    # doc: |
    
    # data(NX_UINT):
    # doc: |
    # Status value of each pixel of the orientation mapping.
    status(N0):
      unit: NX_UNITLESS
      doc: |
        Which return value did the indexing algorithm yield for each scan point.
        Practically useful is to use an uint8 mask.
        
        * 0 - Not analyzed
        * 1 - Too high angular deviation
        * 2 - No solution
        * 100 - Success
        * 255 - Unexpected errors
      dim: (n_sc,)
    n_phases_per_scan_point(N0):
      unit: NX_UNITLESS
      doc: |
        How many phases i.e. crystal structure models were used to index each
        scan point if any? Let's assume an example to explain how this field
        should be used: In the simplest case users collected one pattern for
        each scan point and have indexed using one phase, i.e. one instance
        of an NXem_ebsd_crystal_structure_model.
        
        In another example users may have skipped some scan points (not indexed)
        them at all) and/or used differing numbers of phases for different scan
        points.
        
        The cumulated of this array decodes how phase_identifier and phase_matching
        arrays have to be interpreted. In the simplest case (one pattern per scan
        point, and all scan points indexed using that same single phase model),
        phase_identifier has as many entries as scan points
        and phase_matching has also as many entries as scan points.
      dim: (n_sc,)
    phase_identifier(N0):
      unit: NX_UNITLESS
      doc: |
        The array n_phases_per_scan_point details how the phase_identifier
        and the phase_matching arrays have to be interpreted.
        
        For the example with a single phase phase_identifier has trivial
        values either 0 (no solution) or 1 (solution matching
        sufficiently significant with the model for phase 1).
        
        When there are multiple phases, it is possible (although not frequently
        needed) that a pattern matches eventually (not equally well) sufficiently
        significant with multiple pattern. This can especially happen in cases of
        pseudosymmetry and more frequently with an improperly calibrated system
        or false or inaccurate phase models e.g. (ferrite, austenite).
        Having such field is especially relevant for recent machine learning
        or dictionary based indexing schemes because in combination with
        phase_matching these fields communicate the results in a model-agnostic
        way.
        
        Depending on the n_phases_per_scan_point value phase_identifier and
        phase_matching arrays represent a collection of concatenated tuples,
        which are organized in sequence: The solutions for the 0-th scan point,
        the 1-th scan point, the n_sc - 1 th scan point and omitting tuples
        for those scan points with no phases according to n_phases_per_scan_point
      dim: (i,)
    phase_matching(N0):
      unit: NX_UNITLESS
      doc: |
        One-dimensional array, pattern by pattern labelling the solutions found.
        The array n_phases_per_scan_point has to be specified because it details
        how the phase_identifier and the phase_matching arrays have to be interpreted.
        See documentation of phase_identifier for further details.
      dim: (i,)
    phase_matching_descriptor:
      doc: |
        Phase_matching is a descriptor for how well the solution matches or not.
        Examples can be confidence index (ci), mean angular deviation (mad),
        some AI-based matching probability (other), i.e. the details are implementation-specific.
      enumeration: [undefined, ci, mad, other]
    (NXrotation_set):
    scan_point_positions(R):
      unit: NX_LENGTH
      # we make this only required as people may not yet be so happy with
      # having to walk a graph from measurement -> path -> NXevent_data_em
      # -> em_lab/ebeam_deflector to retrieve the actual scan positions
      # although this would be much cleaner
      doc: |
        Matrix of calibrated center positions of each scan point
        in the sample surface reference system.
      dim: (n_sc, 2)
      # EW ISSUE: this is in fact a duplicate because if we know th
      # path to the measurement we would have available all ebeam_deflector
      # settings and thus could identify where the beam was scanning for each
      # NXevent_data_em instance, we have even more
      # NEW ISSUE: replace by a more generic pivot table
    indexing_rate(R+0):
      unit: NX_DIMENSIONLESS
      doc: |
        Fraction of successfully indexed pattern with a phase not the
        null-phase vs the total number of scan points.
    number_of_scan_points(N0):
      unit: NX_UNITLESS
      doc: |
        Number of scan points in the original mapping.
    (NXms_odf_set):
    (NXms_pf_set):
    (NXms_recon):
    # overview over the entire map, rediscretized on a tight aabb
    roi(NXdata):
      doc: |
        An overview of the entire area which was scanned processed from
        the entire scan area but eventually downsampled.
      descriptor:
        doc: |
          Descriptor representing the image contrast.
        # taking two examples (CTF and H5OINA choked completely of possibility to find s.th. conceptually common to plot
        enumeration: [normalized_band_contrast, normalized_confidence_index]
      # \@signal:  # data
      # \@axes:  # [axis_y, axis_x]
      # \@axis_x_indices: 0
      # \@axis_y_indices: 1
      # \@signal:
      # \@axes:
      # \@AXISNAME_indices:
      # \@long_name:
      title:
        doc: |
          Title of the default plot.
      data(R):
        unit: NX_UNITLESS
        doc: |
          Descriptor values displaying the ROI.
        dim: (n_y, n_x)
        # n_0 slow 2, n_1 fast 1, rgb triplet is fastest 0
        # in axes fast to fastest
        # while for _indices fastest to fast
        \@long_name:
          doc: |
            Descriptor values.
      axis_y(R):
        unit: NX_LENGTH
        doc: |
          Calibrated coordinate along the y-axis.
        dim: (n_y,)
        \@long_name:
          doc: |
            Label for the y axis
      axis_x(R):
        unit: NX_LENGTH
        doc: |
          Calibrated coordinate along the x-axis.
        dim: (n_x,)
        \@long_name:
          doc: |
            Label for the x axis


# BEGIN BLOCK COMMENT
  # clean-up this block of comments
  # definition computation according to backend.
  # AS THE FIRST STEP WE DO NOT IMPLEMENT A GENERIC ORIENTATION AND REFERENCE
  # FRAME LIBRARY WHICH CAN TRANSLATE BETWEEN ALL POSSIBLE CONVENTIONS.
  # INSTEAD WE TAKE THE RESULTS COMPUTED FROM THE BACKEND THAT IS
  # For cpr/crc/ang the pythonEBSD backend
  # For other file either MTex or kikuchipy
  # For DREAM.3D this is DREAM.3D
  # For pyxem following the orix library (which has some, though not yet in
  # all details checked links and usage of the orix library because kikuchipy
  # is somehow connected to pyxem. NEED TO TALK TO DEVELOPERS HERE!
  # NXprogram:
  # The tool/implementation used for creating the IPF color map from
  # the orientation data. Effectively, this program is the backend
  # which performs the computation of the inverse pole figure mappings
  # which can be for some use cases the parser.
  # Consider the explanations in the docstring of the ipf_mapID group.
  # enumeration: [brinckmann, mtex, kikuchipy, dream3d, orix, tsl]

  # correlation(NXprocess):
    # doc: |
      # Apart from single (spot), line, or surface ROIs,
      # correlated measurements are performed.
      
      # One important class of such correlated experiments are the so-called
      # (quasi) in-situ experiments. In this case the same or nearly the same ROI
      # gets analyzed via a repetitive sequence of thermomechanical treatment,
      # sample preparation, measurement, on-the-fly-indexing. Phenomena
      # investigated are recrystallization, strain accumulation, material damage.
      # Post-processing is required to correlate and reidentify eventual
      # microstructural features or local ROIs across several orientation maps.
      
      # Another important class of correlated experiments are the so-called
      # serial-sectioning experiments. Here the same sample is measured
      # repetitively after polishing each time, to create a stack of
      # orientation data which can be reconstructed to a
      # three-dimensional volume ROI.
      
      # Data can be correlated in time, position (spatial), or both (spatiotemporal).
      
      # Spatial correlations between repetitively characterized regions-of-interests
      # are typically correlated using image registration and alignment algorithms.
      # For this typically so-called landmarks are used. These can be grains with
      # a very large size or specific shape, i.e. grains which are qualitatively
      # different enough to be used as a guide how images are shifted relative to
      # one another. Other commonly used landmarks are fiducial marks which are
      # milled into the specimen surface using focus-ion beam milling and/or various
      # types of indentation methods.
      
      # As far as the same physical region-of-interest is just measured several times,
      # the additional issue of the depth increment is not a concern. However, correct
      # assumptions for the depth increment, amount of material removed along the milling
      # direction is relevant for accurate and precise three-dimensional (serial-sectioning)
      # correlations. For these studies it can be tricky though to assume or estimate
      # useful depth increments. Different strategies have been proposed like
      # calibrations, wedged-shaped landmarks and computer simulation assisted
      # assumption making.
      
      # Despite the use of landmarks, there are many practical issues which make the
      # processing of correlations imprecise and inaccurate. Among these are drift
      # and shift of the specimen, instabilities of the holder, the beam, irrespective
      # of the source of the drift, charging effects, here specifically causing local
      # image distortions and rotations which may require special processing algorithms
      # to reduce such imprecisions.
      
      # Time correlations face all of the above-mentioned issues surplus the challenge
      # that specific experimental protocols have to be used to ensure the material state
      # is observed at specific physical time. The example of quasi in-situ characterization
      # of crystal growth phenomena, a common topic in engineering or modern catalysis research
      # makes it necessary to consider that e.g. the target value for the desired annealing
      # temperature is not just gauged based on macroscopic arguments but considers
      # that transient effects take place. Heating or quenching a sample might thus might
      # not have been executed under conditions in the interaction volume as they are
      # documented and/or assumed.
      
      # These issue cause that correlations have an error margin as to how accurately
      # respective datasets were not only just synced based on the geometry of the
      # region-of-interests and the time markers but also to asssure which physical
      # conditions the specimen experienced over the course of the measurements.
      
      # The fourth example of the em_om reference implementation explores the use of the
      # correlation group with a serial-sectioning datasets that was collected by the
      # classical Inconel 100 dataset collected by M. D. Uchic and colleagues
      # (M. Groeber M, Haley BK, Uchic MD, Dimiduk DM, Ghosh S 3d reconstruction and
      # characterization of polycrystalline microstructures using a fib-sem system data set.
      # Mater Charac 2006, 57 259â€“273. 10.1016/j.matchar.2006.01.019M).
      
      # This dataset was specifically relevant in driving forward the implementation
      # of the DREAM.3D software. DREAM.3D is an open-source software project for
      # post-processing and reconstructing, i.e. correlating sets of orientation
      # microscopy data foremost spatially. One focus of the software is the
      # (post-)processing of EBSD datasets. Another cutting edge tool with similar
      # scope but a commercial solution by Bruker is QUBE which was developed by
      # P. Konijnenberg and coworkers.
      
      # Conceptually, software like DREAM.3D supports users with creating linear
      # workflows of post-processing tasks. Workflows can be instructed via the
      # graphical user interface or via so-called pipeline processing via command line
      # calls. DREAM.3D is especially useful because its internal system documents all
      # input, output, and parameter of the processing steps. This makes DREAM.3D a
      # good candidate to interface with tools like em_om parser. Specifically, DREAM.3D
      # documents numerical results via a customized HDF5 file format called DREAM3D.
      # Workflow steps and settings are stored as nested dictionaries in JSON syntax
      # inside a supplementary JSON file or alongside the data in the DREAM3D file.
      # DREAM.3D has a few hundred algorithms implemented. These are called filters
      # in DREAM.3D terminology.
      
      # Users configure a workflow which instructs DREAM.3D to send the data through
      # a chain of predefined and configured filters. Given that for each analysis
      # the filter is documented via its version tags surplus its parameter and setting
      # via a controlled vocabulary, interpreting the content of a DREAM3D HDF5 file
      # is possible in an automated manner using a parser. This makes DREAM.3D analyses
      # repeatable and self-descriptive. A key limitation though is that most frequently
      # the initial set of input data come from commercial files like ANG.
      # This missing link between the provenance of these input files, their associated
      # creation as electron microscope session, is also what NXem_ebsd solves.
      
      # Nevertheless, as this can be solved with e.g. NXem_ebsd we are convinced that
      # the DREAM.3D and the em_om parser can work productively together to realize
      # RDMS-agnostic parsing of serial-section analyses.
      
      # The internal documentation of the DREAM.3D workflow also simplifies the
      # provenance tracking represented by an instance of NXem_ebsd as not every
      # intermediate results has to be stored. Therefore, the fourth example
      # focuses on the key result obtained from DREAM.3D - the reconstructed
      # and aligned three-dimensional orientation map.
      
      # Usually, this result is the starting point for further post-processing
      # and characterization of structural features. As here orientation microscopy
      # is insofar scale invariant using DREAM.3D, NXem_ebsd, and em_om should
      # be useful for different characterization methods, such as EBSD, Transmission
      # Kikuchi Diffraction (TKD), Automated Crystal Orientation Mapping (ACOM),
      # Nanobeam Electron Diffraction (using commercial systems like NanoMegas ASTAR)
      # or open-source implementations of these techniques (such as via pyxem/orix).
      
      # The result of orientation microscopy methods are maps of local orientation
      # and thermodynamic phase (crystal structure) pieces of information. Virtually
      # all post-processing of such results for structural features includes again
      # a workflow of steps which are covered though by the NXms partner application
      # definition. The respective source of the data in an instance of NXms can
      # again be a link or reference to an instance of NXem_ebsd to complete the
      # chain of provenance.
    # # NEW ISSUE: implement support for filters eventually many of them
    # # NEW ISSUE: for now only show that data from DREAM3D can be loaded.
    # # NEW ISSUE: how to handle landmarks
    # # NEW ISSUE: again an entire set of workflows such as rigid or non-rigid
    # # image registration etc.
      # sequence_index(NX_POSINT):
      # (NXem_ebsd_crystal_structure_model):
      # exists: ['min', '1', 'max', 'unbounded']
        # crystallographic_database_identifier:
          # exists: recommended
        # crystallographic_database:
          # exists: recommended
        # unit_cell_abc(NX_FLOAT):
        # unit_cell_alphabetagamma(NX_FLOAT):
        # space_group:
          # exists: recommended
        # phase_identifier(NX_UINT):
        # phase_name:
          # exists: recommended
      
      # # candidate for default plot
      # region_of_interest(NXprocess):
        # exists: ['min', '1', 'max', '1']
        # doc: |
          # An overview of the entire reconstructed volume. For details about
          # what defines the image contrast inspect descriptor.
        # descriptor:
          # doc: |
            # Descriptor representing the image contrast.
        
        # # enumeration: ["normalized_band_contrast", "normalized_confidence_index"]
        # roi(NXdata):
          # doc: |
            # Container holding a default plot of the reconstructed volume.
          
          # # \@signal:  # data
          # # \@axes:  # [axis_z, axis_y, axis_x]
          # # \@axis_x_indices:  # 0
          # # \@axis_y_indices:  # 1
          # # \@axis_z_indices:  # 2
          # \@signal:
          # \@axes:
          # \@AXISNAME_indices:
          
          # # \@long_name:
          # title:
          # data(NX_NUMBER):
            # unit: NX_UNITLESS
            # doc: |
              # Descriptor values displaying the ROI.
            # dimensions:
              # rank: 3
              # dim: [[1, n_z], [2, n_y], [3, n_x]]
            
            # # n_0 slow 2, n_1 fast 1, rgb triplet is fastest 0
            # # in axes fast to fastest
            # # while for _indices fastest to fast
            # \@long_name:
              # doc: |
                # Signal
          # axis_z(NX_NUMBER):
            # unit: NX_LENGTH
            # doc: |
              # Calibrated center of mass of the pixel along the slow axis.
            # dimensions:
              # rank: 1
              # dim: [[1, n_z]]
            # \@long_name:
              # doc: |
                # Label for the z axis
          # axis_y(NX_NUMBER):
            # unit: NX_LENGTH
            # doc: |
              # Calibrated center of mass of the pixel along the fast axis.
            # dimensions:
              # rank: 1
              # dim: [[1, n_y]]
            # \@long_name:
              # doc: |
                # Label for the y axis
          # axis_x(NX_NUMBER):
            # unit: NX_LENGTH
            # doc: |
              # Calibrated center of mass of the pixel along the fastest axis.
            # dimensions:
              # rank: 1
              # dim: [[1, n_x]]
            # \@long_name:
              # doc: |
                # Label for the x axis
      # (NXprocess):
        # exists: ['min', '0', 'max', 'unbounded']
        # doc: |
          # Default inverse pole figure (IPF) plot of the data specific for each
          # phase. No ipf_mapID instances for non-indexed scan points as these are
          # by definition assigned the null phase with phase_identifier 0.
          # The same comments apply as to the two-dimensional representation.
        # phase_identifier(NX_UINT):
          # unit: NX_UNITLESS
          # doc: |
            # Specifying which phase this IPF mapping visualizes.
        # phase_name:
          # doc: |
            # Alias/name for the phase whose indexed scan points are displayed.
        # description:
          # exists: optional
          # doc: |
            # Which IPF definition computation according to backend.
        
        # # NEW ISSUE: [0, 0, 1] is defined in which coordinate system?
        # projection_direction(NX_NUMBER):
          # unit: NX_UNITLESS
          # doc: |
            # Along which axis to project? Typically [0, 0, 1] is chosen.
          # dimensions:
            # rank: 1
            # dim: [[1, 3]]
        # bitdepth(NX_UINT):
          # unit: NX_UNITLESS
          # doc: |
            # Bitdepth used for the RGB color model. Usually 8 bit.
        # (NXprogram):
          # exists: ['min', '1', 'max', 'unbounded']
          # doc: |
            # The tool/implementation used for creating the IPF color map from
            # the orientation data. Effectively, this program is the backend
            # which performs the computation of the inverse pole figure mappings
            # which can be for some use cases the parser.
            # Consider the explanations in the docstring of the ipf_mapID group.
          # program:
            # \@version:
        
        # # enumeration: [brinckmann, mtex, kikuchipy, dream3d, orix, tsl]
        # ipf_rgb_map(NXdata):
          # doc: |
            # The RGB image which represents the IPF map.
          
          # # \@signal:  # rgb
          # # \@axes:  # [zpos, ypos, xpos]  # rgb
          # # \@rgb_indices: 0
          # # \@axis_x_indices: 0
          # # \@axis_y_indices: 1
          # # \@axis_z_indices: 2
          # \@signal:
          # \@axes:
          # \@AXISNAME_indices:
          
          # # \@long_name:
          # title:
          # data(NX_UINT):
            # unit: NX_UNITLESS
            # doc: |
              # RGB array, with resolution per fastest changing value
              # defined by bitdepth.
            # dimensions:
              # rank: 4
              # dim: [[1, n_z], [2, n_y], [3, n_x], [4, 3]]
            
            # # n_p_or_z slow 3, n_y fast 2, n_x faster 1, rgb triplet is fastest 0
            # # in axes fast to fastest
            # # while for _indices fastest to fast
            # \@long_name:
              # doc: |
                # IPF color-coded orientation mapping
          # axis_z(NX_NUMBER):
            # unit: NX_LENGTH
            # doc: |
              # Calibrated center of mass of the pixel along the slow axis.
            # dimensions:
              # rank: 1
              # dim: [[1, n_z]]
            # \@long_name:
              # doc: |
                # Label for the z axis
          
          # # but for h5web RGB we need n_z + 1, was an issue in v6.6.1
          # axis_y(NX_NUMBER):
            # unit: NX_LENGTH
            # doc: |
              # Calibrated center of mass of the pixel along the faster axis.
            # dimensions:
              # rank: 1
              # dim: [[1, n_y]]
            # \@long_name:
              # doc: |
                # Label for the y axis
          
          # # but for h5web RGB we need n_y + 1, was an issue in v6.6.1
          # axis_x(NX_NUMBER):
            # doc: |
              # Calibrated center of mass of the pixel along the fastest axis.
            # dimensions:
              # rank: 1
              # dim: [[1, n_x]]
            # \@long_name:
              # doc: |
                # Label for the x axis
        # ipf_rgb_color_model(NXdata):
          # doc: |
            # Same comments as for the two-dimensional case apply.
          
          # # \@signal:  # rgb
          # # \@axes:  # [ypos, xpos]  # rgb
          # # \@rgb_indices: 0
          # # \@axis_x_indices:  # 0
          # # \@axis_y_indices:  # 1
          # \@signal:
          # \@axes:
          # \@AXISNAME_indices:
          
          # # \@long_name:
          # title:
          # data(NX_UINT):
            # unit: NX_UNITLESS
            # doc: |
              # RGB array, with resolution per fastest changing value defined by bitdepth.
            # dimensions:
              # rank: 3
              # dim: [[1, n_y], [2, n_x], [3, 3]]
            
            # # n_0 slow 2, n_1 fast 1, rgb triplet is fastest 0
            # # in axes fast to fastest
            # # while for _indices fastest to fast
            # \@long_name:
              # doc: |
                # IPF color key in stereographic standard triangle (SST)
          # axis_y(NX_NUMBER):
            # unit: NX_ANY
            # doc: |
              # Pixel coordinate along the slow axis.
            # dimensions:
              # rank: 1
              # dim: [[1, n_y]]
            # \@long_name:
              # doc: |
                # Label for the y axis
          # axis_x(NX_NUMBER):
            # unit: NX_ANY
            # doc: |
              # Pixel coordinate along the fast axis.
            # dimensions:
              # rank: 1
              # dim: [[1, n_x]]
            # \@long_name:
              # doc: |
                # Label for the x axis
# END BLOCK COMMENT

  # further ideas
  # what to do when multiple pattern are averaged into one before the beam moves further?
  # NEW ISSUE: frame averaging
  # NEW ISSUE: going towards the level of suggestions what would all be immediately possible
  # ebsd_mapping(NXprocess):
  # doc: |
  # An EBSD mapping is the result of a collecting and indexing of Kikuchi
  # pattern, so that for each pattern there is either an associated
  # phase_identifier or a status marker stating that no solution was found
  # (NXsst_color_model): ##MK
  # doc: |
  # For each stereographic standard triangle, (fundamental zone) of
  # the orientation space, it is possible to define a color model which
  # associates an orientation in the fundamental zone to a color.
  # For details see:
  # * [G. Nolze et al.](https://doi.org/10.1107/S1600576716012942)
  # * Srikanth Patala and coworkers"'" work and of others.
  # (NXorientation_set):
  # doc: |
  # Collection of quaternions in the SO3 fundamental zone with colors and
  # rgb(NX_NUMBER):
  # doc: RGB colors.
  # unit: NX_UNITLESS
  # dimensions: [[1, n_oris], [2, 3]]
  # hsv and other models
  # (NXcg_point_set):
  # rgb(NX_NUMBER):
  # dimensions: [[1, n_points], [2, 3]]
  # mapping(NX_NUMBER):
  # doc: |
  # The EBSD mapping with colors outlined
  # unit: NX_UNITLESS
  # dimensions: [[1, n_y], [2, n_x], [3, 3]]
  # NEW ISSUE: it would also be possible to define additional color models to overlay
  # check n_p vs n_sc vs n_p_or_z
  
  # confidence_index(NX_FLOAT):
  # doc: |
  # Is a technology-partner-specific (TSL OIM) AMETEK phase_matching descriptor.
  # unit: NX_UNITLESS
  # dimensions:
  # rank: 1
  # dim: [[1, i]]
  # mean_angular_deviation(NX_FLOAT):
  # doc: |
  # The mean angular deviation is also a technology-partner-specific
  # (HKL Channel5) solution-to-reflector matching descriptor.
  # unit: NX_ANGLE
  # dimensions:
  # rank: 1
  # dim: [[1, i]]
  # there are many other type of descriptor especially for new machine learning
  # type and dictionary type indexing methods
  # some descriptors are relevant only for Hough based indexing and technology-partner-specific
  # band_count(NX_UINT):
  # doc: |
  # How many bands were detected in the pattern.
  # unit: NX_UNITLESS
  # dimensions:
  # rank: 1
  # dim: [[1, n_p]]
  # band_minimum(NX_UINT):
  # doc: |
  # Minimum number of bands required to index the pattern
  # unit: NX_UNITLESS
  # dimensions:
  # rank: 1
  # dim: [[1, n_p]]
  # band_maximum(NX_UINT):
  # doc: |
  # Maximum number of bands required to index the pattern
  # unit: NX_UNITLESS
  # dimensions:
  # rank: 1
  # dim: [[1, n_p]]
  # resolution(NX_NUMBER):
  # doc: |
  # Resolution in Hough space.
  # unit: NX_ANGLE  # or NX_ANY
  # band_detection(NXprocess):  # for hough_transform
  # mode:
  # doc: |
  # How are Kikuchi bands detected
  # enumeration: [center]
  # band_contrast(NX_NUMBER):
  # doc: |
  # Value for band contrast descriptor.
  # unit: NX_UNITLESS
  # dimensions:
  # rank: 1
  # dim: [[1, n_p]]
  # band_slope(NX_NUMBER):
  # doc: |
  # Value for band slope descriptor.
  # unit: NX_UNITLESS
  # dimensions:
  # rank: 1
  # dim: [[1, n_p]]
  # centre(NX_FLOAT):
  # doc: |
  # Pattern centre location used for analyzing each pattern.
  # unit: NX_LENGTH
  # dimensions:
  # rank: 2
  # dim: [[1, n_p], [2, 2]]  # what to do when a different one for each pattern seldom but possible
  # distance(NX_FLOAT):
  # doc: |
  # Pattern centre distance used for analyzing each pattern.
  # unit: NX_LENGTH
  # dimensions:
  # rank: 2
  # dim: [[1, n_p], [2, 2]]
  # vh_ratio(NX_FLOAT):
  # doc: |
  # TBD Oxford/HKL Channel 5 CPR files
  # unit: NX_DIMENSIONLESS
  # how to parameterize a group with value, and descriptor type or a
  # field with descriptor type as attribute?
  # pattern_quality(NXprocess):
  # value(NX_NUMBER):
  # doc: |
  # Pattern quality descriptor
  # unit: NX_UNITLESS
  # dimensions:
  # rank: 1
  # dim: [[1, n_p]]
  # model:
  # doc: |
  # Model used to describe some aspect of the pattern.
  # enumeration: [band_contrast, mean_angular_deviation]
  # tilt_angle(NX_FLOAT):
  # maybe better make this integrated into the NXtransformations of the stage_lab, a stage_lab event?
  # beam_position(NXcg_point_set):
  # (NXdetector):
  # exposure_time(NX_FLOAT):
  # unit: NX_TIME
  # gain(NX_FLOAT):
  ##MK how does a gain translate mathematically an input signal into an intensity signal?
  # insertion_distance(NX_FLOAT):
  # unit: NX_LENGTH
  ##MK a coordinate system for the detector in the NXcoordinate_system_set
  # drift_correction(NX_BOOLEAN): ##MK??
  # move the next two rather to detector
  # acquisition_speed(NX_FLOAT):
  # doc: |
  # Average number of patterns taken per second averaged over entire set.
  # unit: NX_FREQUENCY
  # acquisition_time(NX_FLOAT):
  # doc: Wall-clock time the acquisition took.
  # unit: NX_TIME
